{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# REINFORCE\n",
    "Now that we know how to use neural networks in Tensorflow, lets implement our first RL algorithm to solve an RL environment. \n",
    "\n",
    "## LunarLander\n",
    "The environment we will use is the OpenAI Lunar Lander environment. In this environment the agent must safely land a spaceship on the moon by carefully controlling the spaceship's thrusters. Below is a screenshot of the environment. Lets quickly evaluate a random agent on the environment to see how well it does.\n",
    "\n",
    "![Lunar Lander](../images/lunarlander.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "!pip install gym\n",
    "!pip install box2d.py"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: gym in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (0.18.3)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from gym) (1.6.0)\n",
      "Requirement already satisfied: Pillow<=8.2.0 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from gym) (8.2.0)\n",
      "Requirement already satisfied: pyglet<=1.5.15,>=1.4.0 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from gym) (1.5.15)\n",
      "Requirement already satisfied: scipy in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from gym) (1.7.0)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from gym) (1.21.1)\n",
      "Requirement already satisfied: box2d.py in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (2.3.8)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "environment = gym.make(\"LunarLander-v2\")\n",
    "returns = []\n",
    "for i in range(100):\n",
    "    episode_return = 0\n",
    "    observation = environment.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = environment.action_space.sample()\n",
    "\n",
    "        next_observation, reward, done, info = environment.step(action)\n",
    "\n",
    "        episode_return += reward\n",
    "\n",
    "        observation = next_observation\n",
    "\n",
    "    returns.append(episode_return)\n",
    "\n",
    "print(\"Average Return for Random Agent:\", np.average(returns))\n",
    " "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average Return for Random Agent: -170.51265698089665\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "So, a random agent on Lunar Lander gets a score oof around -200. A winning score is +200. To create a winning agent we will implement REINFORCE, the simplest policy gradient RL algorithm.\n",
    "\n",
    "## REINFORCE\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "!pip install tensorflow\n",
    "!pip install tensorflow_probability"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: tensorflow in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (2.5.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from tensorflow) (1.34.1)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: absl-py~=0.10 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from tensorflow) (0.13.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from tensorflow) (3.17.3)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from tensorflow) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard~=2.5 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: cached-property in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow) (2.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow) (1.34.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow) (0.4.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow) (3.10.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.26.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.5->tensorflow) (3.5.0)\n",
      "Collecting tensorflow_probability\n",
      "  Downloading tensorflow_probability-0.13.0-py2.py3-none-any.whl (5.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.4 MB 8.2 MB/s \n",
      "\u001b[?25hCollecting dm-tree\n",
      "  Using cached dm_tree-0.1.6-cp37-cp37m-manylinux_2_24_x86_64.whl (93 kB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from tensorflow_probability) (1.19.5)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from tensorflow_probability) (1.6.0)\n",
      "Requirement already satisfied: gast>=0.3.2 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from tensorflow_probability) (0.4.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from tensorflow_probability) (1.15.0)\n",
      "Requirement already satisfied: decorator in /home/claude/.miniconda3/envs/rl-starter-kit/lib/python3.7/site-packages (from tensorflow_probability) (5.0.9)\n",
      "Installing collected packages: dm-tree, tensorflow-probability\n",
      "Successfully installed dm-tree-0.1.6 tensorflow-probability-0.13.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import numpy as np\n",
    "\n",
    "def reward_to_go(rewards, gamma):\n",
    "    rewards = np.array(rewards)\n",
    "    rewtg = np.zeros_like(rewards, dtype='float32')\n",
    "    T = len(rewards) - 1\n",
    "    rewtg[T] = rewards[T]\n",
    "    for t in range(T-1, -1, -1):\n",
    "        rewtg[t] = rewards[t] + gamma * rewtg[t+1]\n",
    "    return rewtg"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "class REINFORCEAgent():\n",
    "\n",
    "    def __init__(self, act_dim, hidden_size=100, learning_rate=1e-3, gamma=0.9):\n",
    "        self.policy_network = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Dense(hidden_size),\n",
    "                tf.keras.layers.ReLU(),\n",
    "                tf.keras.layers.Dense(act_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        self.gamma = gamma\n",
    "        self.replay_buffer = []\n",
    "\n",
    "    def choose_action(self, observation):\n",
    "        observation = tf.convert_to_tensor(observation)\n",
    "        observation = tf.expand_dims(observation, axis=0)\n",
    "        logits = self.policy_network(observation)\n",
    "        policy = tfp.distributions.Categorical(logits=logits)\n",
    "        action = policy.sample()\n",
    "        return action.numpy()[0]\n",
    "        \n",
    "\n",
    "    def store(self, observation, action, reward, next_observation):\n",
    "        experience_tuple = (observation, action, reward, next_observation)\n",
    "        self.replay_buffer.append(experience_tuple)\n",
    "\n",
    "    def learn(self):\n",
    "        observations, actions, rewards, next_observations = zip(*self.replay_buffer)\n",
    "\n",
    "        observations = tf.convert_to_tensor(observations)\n",
    "        actions = tf.convert_to_tensor(actions)\n",
    "\n",
    "        rewtg = reward_to_go(rewards, self.gamma)\n",
    "        rewtg = tf.convert_to_tensor(rewtg)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = self.policy_network(observations)\n",
    "            policy = tfp.distributions.Categorical(logits=logits)\n",
    "            log_probs = policy.log_prob(actions)\n",
    "\n",
    "            loss = -tf.reduce_sum(log_probs * rewtg)\n",
    "\n",
    "        variables = self.policy_network.trainable_variables\n",
    "        gradients = tape.gradient(loss, variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "        self.replay_buffer = []\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-08-02 15:43:42.023670: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-02 15:43:42.023702: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def run_episode(environment, agent):\n",
    "    episode_return = 0\n",
    "    done = False\n",
    "    observation = environment.reset()\n",
    "    while not done:\n",
    "        action = agent.choose_action(observation)\n",
    "\n",
    "        next_observation, reward, done, info = environment.step(action)\n",
    "\n",
    "        agent.store(observation, action, reward, next_observation)\n",
    "\n",
    "        observation = next_observation\n",
    "\n",
    "        episode_return += reward\n",
    "    \n",
    "    return episode_return\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import gym\n",
    "\n",
    "environment = gym.make(\"LunarLander-v2\")\n",
    "\n",
    "act_dim = environment.action_space.n\n",
    "\n",
    "agent = REINFORCEAgent(act_dim)\n",
    "\n",
    "episode_return = run_episode(environment, agent)\n",
    "print(\"Episode Return:\", episode_return)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-08-02 15:43:52.937823: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-08-02 15:43:52.937855: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-08-02 15:43:52.937877: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (pop-os): /proc/driver/nvidia/version does not exist\n",
      "2021-08-02 15:43:52.938185: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Episode Return: -507.0328812567266\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import datetime\n",
    "\n",
    "class Logger():\n",
    "\n",
    "    def __init__(self, logdir=\"./logs/\"):\n",
    "        current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        logdir = logdir + current_time\n",
    "\n",
    "        self.summary_writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "    def write(self, step, logs):\n",
    "        \"\"\"Write logs to tensorboard.\n",
    "\n",
    "        Args:\n",
    "            step (Int): Training step of the logs.\n",
    "            logs (Dict[str, float]): Dictionary of logs to be written to tensorboard.\n",
    "        \"\"\"\n",
    "        with self.summary_writer.as_default():\n",
    "            for key, value in logs.items():\n",
    "                tf.summary.scalar(key, value, step=step)\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def train(environment, agent, logger, num_iter=5000):\n",
    "    scores = []\n",
    "    for i in range(num_iter):\n",
    "        score = run_episode(environment, agent)\n",
    "        agent.learn()\n",
    "        scores.append(score)\n",
    "\n",
    "        logger.write(step=i, logs={\"return\": score})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "%load_ext tensorboard"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 30024), started 0:00:18 ago. (Use '!kill 30024' to kill it.)"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9b79faa887da4aba\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9b79faa887da4aba\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%tensorboard --logdir logs/"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "logger = Logger()\n",
    "\n",
    "train(environment, agent, logger)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('rl-starter-kit': conda)"
  },
  "interpreter": {
   "hash": "2f1f09945eed0f0215de5d99819a5380b074734dbade509b2a9db3176055ac64"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}